# Deployment Guide

> Comprehensive guide for deploying multi-agent workflows generated by the ADK & Chainlit Agent Builder

## Table of Contents

1. [Overview](#overview)
2. [Local Development](#local-development)
3. [Environment Configuration](#environment-configuration)
4. [Pre-deployment Checklist](#pre-deployment-checklist)
5. [GCP Setup](#gcp-setup)
6. [Deployment Process](#deployment-process)
7. [Post-deployment Verification](#post-deployment-verification)
8. [Troubleshooting](#troubleshooting)
9. [Production Best Practices](#production-best-practices)

---

## Overview

This guide covers the complete deployment lifecycle for multi-agent workflows generated by the Agent Builder:

- **Local Development**: Testing your agents locally before deployment
- **GCP Deployment**: Deploying to Google Cloud Platform with Cloud Run and Agent Engine
- **Production Considerations**: Security, monitoring, and scaling best practices

### What Gets Generated

The Agent Builder generates a complete deployment-ready package:

```
generated-project/
├── main.py              # Chainlit application with ADK agents
├── tools.py             # Agent tools and functions
├── requirements.txt     # Python dependencies
├── Dockerfile           # Container configuration
├── cloudbuild.yaml      # GCP Cloud Build configuration
├── deploy.sh            # Deployment automation script
├── .gcloudignore        # Files to exclude from deployment
└── README.md            # Project-specific setup instructions
```

---

## Local Development

### Prerequisites

- **Python 3.11+** installed
- **pip** package manager
- **Git** for version control (optional)

### Setup Steps

1. **Navigate to your generated project:**
   ```bash
   cd path/to/generated-project
   ```

2. **Create a virtual environment:**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment variables** (see next section)

5. **Run the application:**
   ```bash
   chainlit run main.py -w
   ```

6. **Access the UI:**
   Open your browser to `http://localhost:8000`

### Development Tips

- **Watch mode (`-w`)**: Automatically reloads on code changes
- **Test tools**: Verify each tool function works independently before testing the full workflow
- **Check logs**: Monitor console output for errors and agent responses
- **Validate configuration**: Run preflight checks before deployment

---

## Environment Configuration

### Required Environment Variables

Create a `.env` file in your project root (never commit this file):

```bash
# .env file

# ============================================
# LLM Provider Configuration
# ============================================

# For OpenAI Models (GPT-4, GPT-3.5, etc.)
OPENAI_API_KEY="sk-your-openai-api-key-here"

# For Google Vertex AI Models (Gemini)
# Path to your GCP service account key file
GOOGLE_APPLICATION_CREDENTIALS="/absolute/path/to/service-account-key.json"

# ============================================
# Optional: Memory Bank Configuration
# ============================================
# Only needed if using GCP Memory Bank
# GCP_PROJECT_ID="your-gcp-project-id"
# GCP_REGION="us-central1"

# ============================================
# Optional: Custom Configuration
# ============================================
# PORT=8000  # Default Chainlit port
# CHAINLIT_AUTH_SECRET="your-auth-secret"  # For authentication
```

### Getting API Keys

#### OpenAI API Key
1. Visit [OpenAI API Keys](https://platform.openai.com/api-keys)
2. Click "Create new secret key"
3. Copy the key immediately (you won't see it again)
4. Add to `.env` as `OPENAI_API_KEY`

#### Google Cloud Credentials
1. Go to [GCP Console → IAM & Admin → Service Accounts](https://console.cloud.google.com/iam-admin/serviceaccounts)
2. Select your project
3. Click "Create Service Account"
4. Grant required roles:
   - **Vertex AI User** (for Gemini models)
   - **Memory Bank User** (if using Memory Bank)
5. Click "Keys" → "Add Key" → "Create new key" → "JSON"
6. Download the JSON file
7. Store it securely **outside your project directory**
8. Set `GOOGLE_APPLICATION_CREDENTIALS` to the absolute path

### Security Best Practices

- **Never commit `.env` files** to version control
- **Never commit service account keys** to version control
- **Use absolute paths** for credential files
- **Rotate keys regularly** (every 90 days minimum)
- **Use separate keys** for development and production
- **For production**: Use Google Cloud Secret Manager instead of `.env` files

---

## Pre-deployment Checklist

Before deploying to GCP, verify:

- [ ] **All tests pass locally**
  ```bash
  chainlit run main.py -w
  # Test all agent interactions
  ```

- [ ] **Environment variables configured**
  - API keys are valid
  - Service account has required permissions

- [ ] **Dependencies are up to date**
  ```bash
  pip list --outdated
  ```

- [ ] **Docker builds successfully** (optional local test)
  ```bash
  docker build -t my-agent-test .
  docker run -p 8080:8080 --env-file .env my-agent-test
  ```

- [ ] **GCP project is set up** (see next section)

- [ ] **Billing is enabled** on your GCP project

- [ ] **Required APIs are enabled**

---

## GCP Setup

### 1. Create or Select a GCP Project

```bash
# List existing projects
gcloud projects list

# Create new project (if needed)
gcloud projects create my-agent-project --name="My Agent Project"

# Set active project
gcloud config set project my-agent-project
```

### 2. Enable Required APIs

```bash
# Enable all required APIs
gcloud services enable \
  cloudbuild.googleapis.com \
  artifactregistry.googleapis.com \
  run.googleapis.com \
  aiplatform.googleapis.com \
  --project=my-agent-project
```

**Note**: If using Agent Engine API (not Cloud Run), also enable:
```bash
gcloud services enable agentengine.googleapis.com
```

### 3. Create Artifact Registry Repository

```bash
# Create a Docker repository
gcloud artifacts repositories create agent-engine-repo \
  --repository-format=docker \
  --location=us-central1 \
  --description="Repository for agent Docker images"
```

### 4. Configure IAM Permissions

Ensure your deployment service account has these roles:

```bash
# Get the Cloud Build service account
PROJECT_NUMBER=$(gcloud projects describe my-agent-project --format="value(projectNumber)")
BUILD_SA="${PROJECT_NUMBER}@cloudbuild.gserviceaccount.com"

# Grant necessary roles
gcloud projects add-iam-policy-binding my-agent-project \
  --member="serviceAccount:${BUILD_SA}" \
  --role="roles/run.admin"

gcloud projects add-iam-policy-binding my-agent-project \
  --member="serviceAccount:${BUILD_SA}" \
  --role="roles/iam.serviceAccountUser"

gcloud projects add-iam-policy-binding my-agent-project \
  --member="serviceAccount:${BUILD_SA}" \
  --role="roles/artifactregistry.writer"
```

### 5. Store Secrets in Secret Manager

**Recommended for production:**

```bash
# Enable Secret Manager API
gcloud services enable secretmanager.googleapis.com

# Store OpenAI API key
echo -n "your-openai-api-key" | \
  gcloud secrets create openai-api-key --data-file=-

# Store GCP credentials (if using different project for Vertex AI)
gcloud secrets create gcp-credentials --data-file=./service-account-key.json

# Grant Cloud Run service account access to secrets
gcloud secrets add-iam-policy-binding openai-api-key \
  --member="serviceAccount:${BUILD_SA}" \
  --role="roles/secretmanager.secretAccessor"
```

---

## Deployment Process

### Method 1: Using the Generated Deployment Script (Recommended)

The generated `deploy.sh` script automates the deployment:

```bash
# Review the script first
cat deploy.sh

# Make it executable
chmod +x deploy.sh

# Run deployment
./deploy.sh
```

This script will:
1. Submit the build to Cloud Build
2. Build the Docker image
3. Push to Artifact Registry
4. (Optionally) Deploy to Cloud Run or Agent Engine

### Method 2: Manual Deployment Steps

If you prefer manual control:

#### Step 1: Build and Push Docker Image

```bash
# Set variables
export PROJECT_ID="my-agent-project"
export SERVICE_NAME="my-agent-service"
export REGION="us-central1"

# Build with Cloud Build
gcloud builds submit \
  --config cloudbuild.yaml \
  --project=$PROJECT_ID
```

#### Step 2: Deploy to Cloud Run

```bash
# Deploy the image to Cloud Run
gcloud run deploy $SERVICE_NAME \
  --image=$REGION-docker.pkg.dev/$PROJECT_ID/agent-engine-repo/$SERVICE_NAME:latest \
  --platform=managed \
  --region=$REGION \
  --allow-unauthenticated \
  --set-env-vars="OPENAI_API_KEY=your-key-here" \
  --memory=2Gi \
  --cpu=2 \
  --timeout=300
```

**For production, use Secret Manager instead of `--set-env-vars`:**

```bash
gcloud run deploy $SERVICE_NAME \
  --image=$REGION-docker.pkg.dev/$PROJECT_ID/agent-engine-repo/$SERVICE_NAME:latest \
  --platform=managed \
  --region=$REGION \
  --allow-unauthenticated \
  --set-secrets="OPENAI_API_KEY=openai-api-key:latest" \
  --set-secrets="GOOGLE_APPLICATION_CREDENTIALS=/secrets/gcp-creds=gcp-credentials:latest" \
  --memory=2Gi \
  --cpu=2 \
  --timeout=300
```

### Method 3: Deploying to Agent Engine

If using GCP Agent Engine (specialized for agents):

```bash
# Deploy to Agent Engine
gcloud agent-engine deploy $SERVICE_NAME \
  --image=$REGION-docker.pkg.dev/$PROJECT_ID/agent-engine-repo/$SERVICE_NAME:latest \
  --region=$REGION
```

---

## Post-deployment Verification

### 1. Get the Deployment URL

```bash
# For Cloud Run
gcloud run services describe $SERVICE_NAME \
  --platform=managed \
  --region=$REGION \
  --format="value(status.url)"
```

### 2. Test the Deployment

```bash
# Get the URL
SERVICE_URL=$(gcloud run services describe $SERVICE_NAME \
  --platform=managed \
  --region=$REGION \
  --format="value(status.url)")

# Visit in browser
echo "Visit: $SERVICE_URL"

# Or test with curl
curl $SERVICE_URL
```

### 3. Monitor Logs

```bash
# Stream logs
gcloud run services logs tail $SERVICE_NAME \
  --platform=managed \
  --region=$REGION

# Or use Cloud Console
# https://console.cloud.google.com/run
```

### 4. Verify Agent Responses

1. Open the service URL in your browser
2. Send a test message to your agent
3. Verify:
   - Agent responds correctly
   - Tools are working
   - Memory persists (if using Memory Bank)
   - No errors in logs

---

## Troubleshooting

### Common Issues

#### 1. "Permission Denied" During Build

**Symptom:**
```
ERROR: (gcloud.builds.submit) PERMISSION_DENIED: The caller does not have permission
```

**Solution:**
```bash
# Verify you're authenticated
gcloud auth list

# Re-authenticate if needed
gcloud auth login

# Verify project is set
gcloud config get-value project

# Check your IAM roles
gcloud projects get-iam-policy $(gcloud config get-value project) \
  --flatten="bindings[].members" \
  --filter="bindings.members:user:$(gcloud config get-value account)"
```

#### 2. "API Not Enabled"

**Symptom:**
```
ERROR: API [cloudbuild.googleapis.com] not enabled
```

**Solution:**
```bash
# Enable the specific API mentioned
gcloud services enable cloudbuild.googleapis.com
```

#### 3. Build Succeeds but Service Fails to Start

**Symptom:**
Cloud Run shows "Service Unavailable"

**Solution:**
```bash
# Check logs
gcloud run services logs read $SERVICE_NAME --limit=50

# Common causes:
# - Missing environment variables
# - Port mismatch (ensure Dockerfile uses PORT=8080)
# - Import errors in main.py
# - Missing dependencies in requirements.txt
```

#### 4. OpenAI/Vertex AI Authentication Errors

**Symptom:**
```
OpenAI API Error: Invalid API key
```

**Solution:**
```bash
# For Cloud Run, verify secrets are mounted correctly
gcloud run services describe $SERVICE_NAME --format=yaml

# Check that secrets exist
gcloud secrets list

# Verify service account has access
gcloud secrets get-iam-policy openai-api-key
```

#### 5. Memory Bank Connection Issues

**Symptom:**
```
Error: Cannot connect to Memory Bank
```

**Solution:**
```bash
# Ensure Memory Bank API is enabled
gcloud services enable aiplatform.googleapis.com

# Verify service account has required role
gcloud projects add-iam-policy-binding $PROJECT_ID \
  --member="serviceAccount:YOUR_SA@$PROJECT_ID.iam.gserviceaccount.com" \
  --role="roles/aiplatform.user"
```

---

## Production Best Practices

### Security

1. **Use Secret Manager** for all sensitive data
   - Never hardcode API keys in environment variables
   - Rotate secrets regularly

2. **Enable Authentication**
   ```bash
   # Require authentication for Cloud Run
   gcloud run services update $SERVICE_NAME \
     --no-allow-unauthenticated
   ```

3. **Use VPC Connector** for internal services
   ```bash
   gcloud run services update $SERVICE_NAME \
     --vpc-connector=my-connector \
     --vpc-egress=private-ranges-only
   ```

4. **Enable Binary Authorization**
   - Only deploy signed container images

5. **Set up IAM Conditions**
   - Time-based access
   - IP-based restrictions

### Monitoring

1. **Enable Cloud Monitoring**
   ```bash
   gcloud services enable monitoring.googleapis.com
   ```

2. **Create Alerts**
   - High error rates
   - Slow response times
   - High memory/CPU usage
   - API quota limits

3. **Set up Log-based Metrics**
   ```bash
   # Example: Track agent errors
   gcloud logging metrics create agent-errors \
     --description="Count of agent errors" \
     --log-filter='resource.type="cloud_run_revision"
                   severity>=ERROR'
   ```

4. **Use Cloud Trace** for performance analysis

### Scaling

1. **Configure Autoscaling**
   ```bash
   gcloud run services update $SERVICE_NAME \
     --min-instances=1 \
     --max-instances=100 \
     --concurrency=80
   ```

2. **Set Resource Limits**
   ```bash
   gcloud run services update $SERVICE_NAME \
     --memory=4Gi \
     --cpu=4 \
     --timeout=900
   ```

3. **Use CDN** for static assets (if applicable)

### Cost Optimization

1. **Set Minimum Instances to 0** for dev/staging
   ```bash
   gcloud run services update $SERVICE_NAME --min-instances=0
   ```

2. **Monitor Costs**
   - Set up budget alerts
   - Use Cost Breakdown by service

3. **Optimize Container Size**
   - Use multi-stage builds
   - Remove unnecessary dependencies

4. **Use Committed Use Discounts** for predictable workloads

### Reliability

1. **Set up Health Checks**
   ```python
   # Add to main.py
   @cl.on_settings_update
   async def health_check():
       return {"status": "healthy"}
   ```

2. **Enable Graceful Shutdown**
   - Handle SIGTERM signals
   - Complete in-flight requests

3. **Use Regional Deployment** for high availability

4. **Implement Circuit Breakers** for external API calls

### CI/CD Integration

Example GitHub Actions workflow:

```yaml
name: Deploy to Cloud Run

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v1

      - name: Deploy
        run: |
          gcloud builds submit --config cloudbuild.yaml
```

---

## Next Steps

- Review [TROUBLESHOOTING.md](./TROUBLESHOOTING.md) for additional help
- Check [SECURITY.md](./SECURITY.md) for security guidelines
- See [API_DOCUMENTATION.md](./API_DOCUMENTATION.md) for API details
- Explore [WORKFLOW_GUIDE.md](./WORKFLOW_GUIDE.md) for workflow patterns

---

## Support

- **Documentation**: Check the generated `README.md` in your project
- **GCP Documentation**: [Cloud Run Docs](https://cloud.google.com/run/docs)
- **Chainlit Docs**: [Chainlit Documentation](https://docs.chainlit.io)
- **ADK Docs**: [Agent Development Kit](https://github.com/google/adk)

---

**Last Updated**: 2025-10-22
