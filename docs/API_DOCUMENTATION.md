# Generated Code API Documentation

This document explains the structure and API of the Python code generated by the ADK & Chainlit Agent Builder.

## Table of Contents

- [File Structure](#file-structure)
- [Main Components](#main-components)
- [Tools API](#tools-api)
- [Agent Configuration](#agent-configuration)
- [Workflow Types](#workflow-types)
- [Environment Variables](#environment-variables)
- [Chainlit UI Customization](#chainlit-ui-customization)

## File Structure

The generated codebase includes the following files:

```
multi-agent-workflow/
â”œâ”€â”€ main.py              # Main application entry point
â”œâ”€â”€ tools.py             # Tool definitions and implementations
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ README.md            # Setup and deployment instructions
â”œâ”€â”€ Dockerfile           # Container configuration
â”œâ”€â”€ .gcloudignore        # Files to exclude from GCP deployment
â”œâ”€â”€ cloudbuild.yaml      # GCP Cloud Build configuration (if GCP enabled)
â””â”€â”€ deploy.sh            # GCP deployment script (if GCP enabled)
```

## Main Components

### main.py

The main application file that sets up agents, tools, and the Chainlit UI.

**Key Functions:**

#### `setup_agent()`

Creates and configures a single agent.

```python
def setup_agent(
    name: str,
    system_prompt: str,
    llm_model: str = "gemini-1.5-flash",
    temperature: float = 0.7,
    tools: List[Tool] = []
) -> Agent:
    """
    Set up an agent with specified configuration.

    Args:
        name: Agent name (must be unique)
        system_prompt: Instructions for the agent's behavior
        llm_model: LLM model to use (e.g., "gemini-1.5-flash", "gpt-4o")
        temperature: Sampling temperature (0.0-1.0)
        tools: List of tools available to the agent

    Returns:
        Configured Agent instance
    """
```

**Example:**
```python
agent = setup_agent(
    name="CustomerSupport",
    system_prompt="You are a helpful customer support assistant.",
    llm_model="gemini-1.5-flash",
    temperature=0.7,
    tools=[get_weather, search_database]
)
```

#### `@cl.on_chat_start`

Chainlit lifecycle hook called when a new chat session starts.

```python
@cl.on_chat_start
async def start():
    """
    Initialize the chat session.

    Sets up the agent(s) and stores them in the user session.
    Sends welcome message to the user.
    """
```

#### `@cl.on_message`

Chainlit lifecycle hook called for each user message.

```python
@cl.on_message
async def main(message: cl.Message):
    """
    Process user messages through the agent.

    Args:
        message: Incoming message from the user

    Streams agent responses back to the UI.
    """
```

## Tools API

### tools.py

Defines tools that agents can use. Each tool consists of:
1. **Input Model** (Pydantic): Validates and types tool parameters
2. **Tool Function**: Implements the tool's logic
3. **Tool Definition**: ADK Tool object that wraps the function

### Tool Structure

**Input Model:**
```python
class ToolNameInput(BaseModel):
    """Input model for tool_name tool."""

    parameter_name: str = Field(
        ...,  # Required parameter
        description="Parameter description"
    )
    optional_param: typing.Optional[int] = Field(
        None,  # Optional parameter
        description="Optional parameter description"
    )
```

**Tool Function:**
```python
def tool_name(params: ToolNameInput) -> str:
    """
    Tool implementation.

    Args:
        params: Validated input parameters

    Returns:
        String result that will be passed back to the agent

    Raises:
        Exception: If tool execution fails
    """
    # Implementation
    return "Result"
```

**Tool Definition:**
```python
tool_name_tool = Tool(
    name="tool_name",
    description="What this tool does",
    fn=tool_name,
    input_model=ToolNameInput
)
```

### Built-in Example: Weather Tool

The generator includes an example weather tool:

```python
class GetWeatherInput(BaseModel):
    """Input for get_weather tool."""
    location: str = Field(..., description="City name")

def get_weather(params: GetWeatherInput) -> str:
    """
    Get current weather for a location.

    Uses Open-Meteo API (no API key required).

    Args:
        params: Location to check weather for

    Returns:
        Weather description string
    """
    # Implementation using requests
    # Returns formatted weather string
```

**Usage in Agent:**
```python
agent = setup_agent(
    name="WeatherBot",
    system_prompt="Provide weather information.",
    tools=[get_weather]
)
```

### Creating Custom Tools

1. **Define Input Model:**
```python
class MyToolInput(BaseModel):
    query: str = Field(..., description="Search query")
    max_results: typing.Optional[int] = Field(
        10,
        description="Maximum results"
    )
```

2. **Implement Function:**
```python
def my_tool(params: MyToolInput) -> str:
    query = params.query
    max_results = params.max_results

    # Your implementation
    results = do_search(query, limit=max_results)

    return f"Found {len(results)} results"
```

3. **Create Tool Definition:**
```python
my_tool_def = Tool(
    name="my_tool",
    description="Searches the database",
    fn=my_tool,
    input_model=MyToolInput
)
```

4. **Add to Agent:**
```python
agent = setup_agent(
    name="SearchBot",
    tools=[my_tool_def]
)
```

## Agent Configuration

### Agent Properties

```python
Agent(
    name="AgentName",           # Unique identifier
    system_prompt="...",         # Instructions/personality
    llm_model="gemini-1.5-flash", # LLM to use
    temperature=0.7,             # Creativity (0.0-1.0)
    tools=[...],                 # Available tools

    # Optional LLM parameters
    top_p=0.95,                  # Nucleus sampling
    max_tokens=2048,             # Max response length
)
```

### LLM Model Options

Supported models:

**Gemini (Google):**
- `gemini-2.5-flash` - Latest, fastest
- `gemini-1.5-flash` - Fast, cost-effective
- `gemini-1.5-pro` - Most capable

**GPT (OpenAI):**
- `gpt-4o` - Most capable OpenAI model

### Temperature Guidelines

- `0.0-0.3`: Deterministic, factual responses
- `0.4-0.7`: Balanced creativity and consistency
- `0.8-1.0`: Highly creative, more varied responses

## Workflow Types

### Sequential Workflow

Agents process requests in order, each seeing the previous agent's output.

```python
# Generated code structure
agents = [
    setup_agent(name="Agent1", ...),
    setup_agent(name="Agent2", ...),
    setup_agent(name="Agent3", ...),
]

# User message flows: User â†’ Agent1 â†’ Agent2 â†’ Agent3 â†’ User
```

**Use Cases:**
- Multi-step processing pipelines
- Data transformation chains
- Progressive refinement

### Hierarchical Workflow

Supervisor agent delegates to subordinate agents.

```python
# Generated code structure
supervisor = setup_agent(name="Supervisor", ...)

worker1 = setup_agent(
    name="Worker1",
    parent=supervisor,  # Links to supervisor
    ...
)

worker2 = setup_agent(
    name="Worker2",
    parent=supervisor,
    ...
)
```

**Use Cases:**
- Task delegation
- Specialized sub-agents
- Parallel processing with coordination

### Collaborative Workflow

Agents work together, sharing context and coordinating.

```python
# Generated code structure
agents = [
    setup_agent(name="Agent1", ...),
    setup_agent(name="Agent2", ...),
]

# Agents can communicate and share information
```

**Use Cases:**
- Multi-perspective analysis
- Consensus building
- Complex problem solving

## Environment Variables

### Required Variables

Create a `.env` file in the project root:

```bash
# Required: API key for LLM provider
GEMINI_API_KEY=your_gemini_api_key_here

# Or for OpenAI models
OPENAI_API_KEY=your_openai_api_key_here

# For GCP deployment (optional in local dev)
GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account-key.json
```

### Optional Variables

```bash
# Chainlit configuration
CHAINLIT_PORT=8000
CHAINLIT_AUTH_SECRET=random_secret_string

# Development
DEBUG=true
LOG_LEVEL=INFO
```

### Loading Environment Variables

The generated code automatically loads variables:

```python
from dotenv import load_dotenv
import os

load_dotenv()  # Loads .env file

api_key = os.getenv("GEMINI_API_KEY")
```

## Chainlit UI Customization

### Welcome Message

Customize in the generated `main.py`:

```python
@cl.on_chat_start
async def start():
    # Custom welcome message
    await cl.Message(
        content="ðŸ‘‹ Welcome! How can I help you today?"
    ).send()
```

### Message Styling

```python
# Send message with different types
await cl.Message(content="Regular message").send()

await cl.Message(
    content="Success!",
    type="success"  # or "error", "warning", "info"
).send()
```

### Adding Elements

```python
# Send image
image = cl.Image(path="path/to/image.png", name="image")
await cl.Message(content="Check this out:", elements=[image]).send()

# Send file
file = cl.File(path="data.csv", name="data.csv")
await cl.Message(content="Here's the file:", elements=[file]).send()
```

### User Input

```python
# Ask for specific input
response = await cl.AskUserMessage(
    content="What's your email?",
    timeout=30
).send()

email = response['content']
```

### Session State

```python
# Store data in user session
cl.user_session.set("user_name", "John")

# Retrieve data
name = cl.user_session.get("user_name")
```

## Modifying Generated Code

### Adding New Tools

1. Edit `tools.py`:
```python
# Add your tool implementation
class NewToolInput(BaseModel):
    param: str = Field(..., description="...")

def new_tool(params: NewToolInput) -> str:
    # Implementation
    return "result"

new_tool_def = Tool(
    name="new_tool",
    description="...",
    fn=new_tool,
    input_model=NewToolInput
)
```

2. Update `main.py`:
```python
from tools import get_weather, new_tool  # Add import

agent = setup_agent(
    name="Agent",
    tools=[get_weather, new_tool]  # Add to tools list
)
```

### Modifying Agent Behavior

Edit the `system_prompt` in `main.py`:

```python
agent = setup_agent(
    name="Agent",
    system_prompt="""
    You are a specialized assistant that:
    1. Always responds politely
    2. Uses tools when needed
    3. Asks clarifying questions
    4. Provides structured responses
    """,
    ...
)
```

### Adding Dependencies

1. Edit `requirements.txt`:
```txt
chainlit
requests
google-cloud-aiplatform
your-new-dependency==1.0.0
```

2. Reinstall:
```bash
pip install -r requirements.txt
```

## Best Practices

### Tool Design

1. **Clear descriptions**: Help the LLM understand when to use the tool
2. **Validate inputs**: Use Pydantic models strictly
3. **Handle errors**: Return informative error messages
4. **Keep tools focused**: One tool = one responsibility

### Agent Configuration

1. **Specific prompts**: Be explicit about agent behavior
2. **Appropriate temperature**: Match to use case
3. **Tool selection**: Only include relevant tools
4. **Test iteratively**: Refine prompts based on behavior

### Error Handling

```python
def my_tool(params: MyToolInput) -> str:
    try:
        result = risky_operation(params.query)
        return f"Success: {result}"
    except Exception as e:
        # Return error to agent, not to user directly
        return f"Error: {str(e)}"
```

### Logging

```python
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def my_tool(params: MyToolInput) -> str:
    logger.info(f"Tool called with: {params.query}")
    # Implementation
```

## API Reference Quick Links

- [ADK Documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-builder/adk/overview)
- [Chainlit Documentation](https://docs.chainlit.io/)
- [Pydantic Documentation](https://docs.pydantic.dev/)

---

**Need help?** See the [Troubleshooting Guide](./TROUBLESHOOTING.md) for common issues and solutions.
