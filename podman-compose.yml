version: '3.8'

services:
  # Main Application Service (Backend API + Chainlit)
  chainlit-adk:
    build:
      context: .
      dockerfile: Containerfile
    image: chainlit-adk-wysiwyg:latest
    container_name: chainlit-adk-wysiwyg
    restart: unless-stopped

    ports:
      - "3001:3001"  # Backend API
      - "8000:8000"  # Chainlit Server

    environment:
      # Required
      - GEMINI_API_KEY=${GEMINI_API_KEY}

      # Optional - OpenAI
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}

      # Server Configuration
      - NODE_ENV=production
      - BACKEND_PORT=3001
      - CHAINLIT_PORT=8000

      # GCP Configuration (Optional)
      - GCP_PROJECT_ID=${GCP_PROJECT_ID:-}
      - GCP_REGION=${GCP_REGION:-us-central1}

      # Debug
      - DEBUG=${DEBUG:-false}

    # Mount volumes for persistent data
    volumes:
      # Persist generated Chainlit applications
      - chainlit-data:/app/chainlit_app

      # Optional: Mount local .env file (if you prefer file-based config)
      # - ./.env.local:/app/.env.local:ro

    # Health check
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3001/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

    # Resource limits (adjust based on your needs)
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

    # Logging configuration
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

    # Network configuration
    networks:
      - chainlit-network

networks:
  chainlit-network:
    driver: bridge

volumes:
  chainlit-data:
    driver: local
